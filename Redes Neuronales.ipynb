{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.3935 - acc: 0.8840\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2054 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1590 - acc: 0.9522\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1331 - acc: 0.9597\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1140 - acc: 0.9643\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0996 - acc: 0.9685\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0899 - acc: 0.9711\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0815 - acc: 0.9738\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0727 - acc: 0.9763\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0667 - acc: 0.9779\n",
      "10000/10000 [==============================] - 0s 18us/step\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=10,\n",
    "  batch_size=64,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")\n",
    "\n",
    "# Save the model to disk.\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "# Load the model from disk later using:\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "# Predict on the first 15 test images.\n",
    "predictions = model.predict(test_images[:15])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1))\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
